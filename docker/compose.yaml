services:
  jellyfin:
    image: jellyfin/jellyfin
    container_name: jellyfin
    volumes:
      - jellyfin:/config:/config
      - jellyfin:/cache:/cache
      - ${JELLYFIN_DATA_PATH}:/media:rw
    ports:
      - ${JELLYFIN_PORT_WEB}:8096
    environment:
      - USER_UID=1000
      - USER_GID=1000
    env_file:
      - docker.env
    restart: unless-stopped

  gitea:
    image: gitea/gitea
    container_name: gitea
    volumes:
      - ${GITEA_DATA_PATH}/gitea:/data
    ports:
      - ${GITEA_PORT_WEB}:3000
      - ${GITEA_PORT_SSH}:22
    environment:
      - USER_UID=1000
      - USER_GID=1000
    env_file:
      - docker.env
    restart: unless-stopped

  immich-server:
    container_name: immich_server
    image:  ghcr.io/immich-app/immich-server:release
    volumes:
      - ${IMMICH_EXTERNAL_IMAGES_PATH}:/usr/src/app/external:ro
      - ${IMMICH_THUMBNAILS_PATH}:/usr/src/app/upload
    ports:
      - ${IMMICH_PORT_WEB}:3001
    depends_on:
      - redis
      - database
    env_file:
      - docker.env
    healthcheck:
      disable: false
    restart: unless-stopped

  immich-machine-learning:
    container_name: immich_machine_learning
    # For hardware acceleration, add one of -[armnn, cuda, openvino] to the image tag.
    # Example tag: ${IMMICH_VERSION:-release}-cuda
    image: ghcr.io/immich-app/immich-machine-learning:release
    # extends: # uncomment this section for hardware acceleration - see https://immich.app/docs/features/ml-hardware-acceleration
    #   file: hwaccel.ml.yml
    #   service: cpu # set to one of [armnn, cuda, openvino, openvino-wsl] for accelerated inference - use the `-wsl` version for WSL2 where applicable
    volumes:
      - model-cache:/cache
    env_file:
      - docker.env
    healthcheck:
      disable: false
    restart: unless-stopped

  redis:
    container_name: immich_redis
    image: registry.hub.docker.com/library/redis:latest
    healthcheck:
      test: redis-cli ping || exit 1
    restart: unless-stopped

  database:
    container_name: immich_postgres
    image: docker.io/tensorchord/pgvecto-rs:pg14-v0.2.0@sha256:90724186f0a3517cf6914295b5ab410db9ce23190a2d9d0b9dd6463e3fa298f0
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_DB: ${DB_DATABASE_NAME}
      POSTGRES_INITDB_ARGS: '--data-checksums'
    volumes:
      - pgdata:/var/lib/postgresql/data
    env_file:
      - docker.env
    healthcheck:
      test: >-
        pg_isready --dbname="$${POSTGRES_DB}" --username="$${POSTGRES_USER}" || exit 1;
        Chksum="$$(psql --dbname="$${POSTGRES_DB}" --username="$${POSTGRES_USER}" --tuples-only --no-align
        --command='SELECT COALESCE(SUM(checksum_failures), 0) FROM pg_stat_database')";
        echo "checksum failure count is $$Chksum";
        [ "$$Chksum" = '0' ] || exit 1
      interval: 5m
      start_interval: 30s
      start_period: 5m
    command: >-
      postgres
      -c shared_preload_libraries=vectors.so
      -c 'search_path="$$user", public, vectors'
      -c logging_collector=on
      -c max_wal_size=2GB
      -c shared_buffers=512MB
      -c wal_compression=on
    restart: unless-stopped

  watchtower:
    image: containrrr/watchtower
    container_name: watchtower
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    restart: unless-stopped

  grafana:
    image: grafana/grafana-oss
    container_name: grafana
    ports:
      - ${GRAFANA_PORT_WEB}:3000
    volumes:
      - grafana-data:/var/lib/grafana
      - grafana-config:/etc/grafana
    env_file:
      - docker.env
    restart: unless-stopped

  # When you will add prometheus in grafana, the connection url will be http://prometheus:9090
  prometheus:
    image: prom/prometheus
    container_name: prometheus
    ports:
      - 127.0.0.1:${PROMETHEUS_PORT_WEB}:9090
    volumes:
      - prom-data:/prometheus    
      - ${PROMETHEUS_PATH}:/etc/prometheus
    env_file:
      - docker.env
    restart: unless-stopped

  node_exporter:
    image: prom/node-exporter
    container_name: node_exporter
    command:
      - '--path.rootfs=/host'
    pid: host
    ports:
      - 127.0.0.1:${NODE_EXPORTER_PORT}:9100
    volumes:
      - '/:/host:ro'      
    env_file:
      - docker.env
    restart: unless-stopped

  tailscale-nginx:
    image: tailscale/tailscale:stable
    container_name: tailscale-nginx 
    hostname: ${TAILSCALE_HOSTNAME}
    environment:
      - TS_AUTHKEY=${TAILSCALE_AUTHKEY}
      - TS_EXTRA_ARGS=--advertise-tags=tag:${TAILSCALE_TAG}
      - TS_STATE_DIR=/var/lib/tailscale
      - TS_USERSPACE=false
    volumes:
      - tailscale-nginx:/var/lib/tailscale
      - /dev/net/tun:/dev/net/tun
    cap_add:
      - net_admin
      - sys_module
    restart: unless-stopped

  nginx:
    image: nginx
    depends_on:
      - tailscale-nginx
    network_mode: service:tailscale-nginx

volumes:
  pgdata:
  model-cache:
  etc_wireguard:
  grafana-data:
  grafana-config:
  prom-data:    
  tailscale-nginx:
  jellyfin:
